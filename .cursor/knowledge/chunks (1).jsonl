{"entry_id": "langgraph_durable_agents", "chunk_id": "k_langgraph_durable_agents_1", "text": "LangGraph is a low-level orchestration framework used by companies like Klarna, Replit, and Elastic to build, manage, and deploy long-running, stateful agents. Its key benefits include durable execution with automatic resumption after failure, human-in-the-loop control, comprehensive memory for short and long-term state, debugging tools via LangSmith, and production-ready deployment\u3010525475077813679\u2020L22-L25\u3011\u3010525475077813679\u2020L65-L90\u3011.", "summary": "LangGraph is a low-level orchestration framework used by companies like Klarna, Replit, and Elastic to build, manage, and deploy long-running, stateful agents", "tags": ["orchestration", "agents"], "citations": [{"source_id": "s_langgraph", "locator": "L22-L25"}, {"source_id": "s_langgraph", "locator": "L65-L90"}]}
{"entry_id": "agentic_rag", "chunk_id": "k_agentic_rag_1", "text": "Agentic RAG embeds autonomous agents into RAG pipelines to overcome the limitations of traditional retrieval-augmented generation. The technique employs agentic patterns such as reflection, planning, tool use, and multi-agent collaboration to handle dynamic, multi-step reasoning tasks and adaptive workflows\u3010211515308209869\u2020L40-L50\u3011\u3010211515308209869\u2020L90-L104\u3011.", "summary": "Agentic RAG embeds autonomous agents into RAG pipelines to overcome the limitations of traditional retrieval-augmented generation", "tags": ["retrieval", "agentic-rag"], "citations": [{"source_id": "s_agentic_rag_survey", "locator": "L40-L50"}, {"source_id": "s_agentic_rag_survey", "locator": "L90-L104"}]}
{"entry_id": "faiss_index_selection", "chunk_id": "k_faiss_index_selection_1", "text": "FAISS offers multiple index types for approximate nearest neighbor search. IndexHNSWFlat uses a Hierarchical Navigable Small World (HNSW) graph to provide fast approximate nearest neighbor search. IndexIVFFlat partitions vectors into inverted lists and performs exact distance computations within selected lists, trading recall for speed. Product quantization (PQ) compresses vectors using codebooks to reduce memory footprint and accelerate search\u3010248501046452647\u2020L193-L205\u3011.", "summary": "FAISS offers multiple index types for approximate nearest neighbor search", "tags": ["vector search", "faiss"], "citations": [{"source_id": "s_faiss", "locator": "L193-L205"}]}
{"entry_id": "opentelemetry_signals", "chunk_id": "k_opentelemetry_signals_1", "text": "OpenTelemetry defines four primary signals\u2014traces, metrics, logs, and baggage. Traces represent the path of a request through an application; metrics are runtime measurements; logs record events; and baggage carries contextual information across signals\u3010825539065151992\u2020L767-L781\u3011. Correlating these signals allows developers to link logs to specific traces or metrics, providing end-to-end visibility for debugging and monitoring.", "summary": "OpenTelemetry defines four primary signals\u2014traces, metrics, logs, and baggage", "tags": ["observability", "otel"], "citations": [{"source_id": "s_opentelemetry_signals", "locator": "L767-L781"}]}
{"entry_id": "data_versioning", "chunk_id": "k_data_versioning_1", "text": "Machine-learning systems need versioning for code, training/testing datasets, model artifacts and configuration files to achieve reproducibility, traceability and compliance. Best practices include storing all artefacts and linking data versions with unique identifiers; using metadata and tests for data quality; and utilising tools like MLflow Model Registry to manage model versions, lineage and metadata tags\u3010305081854022075\u2020L18-L49\u3011\u3010608503941462639\u2020L56-L90\u3011.", "summary": "Machine-learning systems need versioning for code, training/testing datasets, model artifacts and configuration files to achieve reproducibility, traceability and compliance", "tags": ["data", "versioning"], "citations": [{"source_id": "s_seml_data", "locator": "L18-L49"}, {"source_id": "s_mlflow_registry", "locator": "L56-L90"}]}
{"entry_id": "data_governance", "chunk_id": "k_data_governance_1", "text": "Data governance should involve not only developers but also data contributors and affected communities and must be considered throughout the machine-learning pipeline. When using web-scraped or third-party data, teams should respect copyright and licensing requirements and ensure consent; only use data with compatible licences\u3010196347673918349\u2020L68-L84\u3011\u3010196347673918349\u2020L122-L133\u3011. Datasheets for Datasets provide a structured way to document the motivation, collection methods, composition and legal considerations of a dataset\u3010196347673918349\u2020L137-L144\u3011.", "summary": "Data governance should involve not only developers but also data contributors and affected communities and must be considered throughout the machine-learning pipeline", "tags": ["data governance", "compliance"], "citations": [{"source_id": "s_turing_governance", "locator": "L68-L84"}, {"source_id": "s_turing_governance", "locator": "L122-L133"}, {"source_id": "s_turing_governance", "locator": "L137-L144"}]}
{"entry_id": "model_tuning", "chunk_id": "k_model_tuning_1", "text": "As large language models grow, full fine-tuning becomes expensive. Low-Rank Adaptation (LoRA) freezes pre-trained weights and injects trainable low-rank matrices into each Transformer layer, reducing trainable parameters by up to 10,000\u00d7 and memory usage by 3\u00d7 while achieving comparable or better performance than full fine-tuning\u3010372047554543751\u2020L53-L62\u3011.", "summary": "As large language models grow, full fine-tuning becomes expensive", "tags": ["fine-tuning", "LoRA"], "citations": [{"source_id": "s_lora", "locator": "L53-L62"}]}
{"entry_id": "inference_optimization", "chunk_id": "k_inference_optimization_1", "text": "Efficient inference for large language models can be significantly improved by dynamic batching, micro-batching and attention optimizations. Dynamic batching continuously schedules new requests into running batches, reducing latency and improving throughput; for example, dynamic batching reduced latency from 976 ms to 126 ms on a 7B model at batch size eight\u3010190212981021054\u2020L432-L441\u3011. Techniques such as paged attention and continuous batching further enhance throughput by reusing key-value caches.", "summary": "Efficient inference for large language models can be significantly improved by dynamic batching, micro-batching and attention optimizations", "tags": ["inference", "dynamic batching"], "citations": [{"source_id": "s_clarifai", "locator": "L432-L441"}]}
{"entry_id": "ux_prompting", "chunk_id": "k_ux_prompting_1", "text": "Prompting is both a creative brief and a conversation script. Effective prompt design requires guiding the AI like a \u2018smart, eager intern\u2019 rather than expecting it to act autonomously; designers should coach the model, set tone and scope, and verify outputs\u3010256666701899297\u2020L89-L96\u3011\u3010256666701899297\u2020L99-L104\u3011. Prompts should be tailored to your goals and style instead of relying on generic templates, and should never include sensitive or private information\u3010256666701899297\u2020L112-L130\u3011.", "summary": "Prompting is both a creative brief and a conversation script", "tags": ["prompting", "UX"], "citations": [{"source_id": "s_smashing", "locator": "L89-L96"}, {"source_id": "s_smashing", "locator": "L99-L104"}, {"source_id": "s_smashing", "locator": "L112-L130"}]}
{"entry_id": "mlops_ci", "chunk_id": "k_mlops_ci_1", "text": "MLOps combines machine-learning development with DevOps to automate and streamline the ML lifecycle. Good practices include version control and reproducibility for data and models, continuous integration and delivery (CI/CD) with automated testing, scalability, resource efficiency, cross-team collaboration, compliance and governance, and continuous monitoring for concept drift\u3010727963589186650\u2020L113-L200\u3011.", "summary": "MLOps combines machine-learning development with DevOps to automate and streamline the ML lifecycle", "tags": ["mlops", "ci/cd"], "citations": [{"source_id": "s_harness", "locator": "L113-L200"}]}
{"entry_id": "evaluation_benchmarks", "chunk_id": "k_evaluation_benchmarks_1", "text": "Evaluating AI systems requires both offline benchmarks and online experiments. AGIEval is a human-centric benchmark derived from 20 official exams (such as the Gaokao, SAT and law school entrance tests) that tests foundation models on tasks relevant to human cognition and problem solving\u3010806806079254338\u2020L59-L66\u3011. Evaluation criteria include accuracy, latency, cost and hit rate.", "summary": "Evaluating AI systems requires both offline benchmarks and online experiments", "tags": ["evaluation", "benchmark"], "citations": [{"source_id": "s_agieval", "locator": "L59-L66"}]}
{"entry_id": "security_guidelines", "chunk_id": "k_security_guidelines_1", "text": "Secure LLM applications require defending against prompt injection, model poisoning, data leakage, and other vulnerabilities. The OWASP Top 10 for LLM applications recommends mitigation strategies such as strict context management, input validation, output filtering, adversarial testing, sensitive information redaction, supply-chain security, permission gating for tools, and isolating system prompts\u3010326855334241198\u2020L172-L190\u3011\u3010326855334241198\u2020L195-L303\u3011.", "summary": "Secure LLM applications require defending against prompt injection, model poisoning, data leakage, and other vulnerabilities", "tags": ["security", "OWASP"], "citations": [{"source_id": "s_owasp", "locator": "L172-L190"}, {"source_id": "s_owasp", "locator": "L195-L303"}]}
{"entry_id": "compliance", "chunk_id": "k_compliance_1", "text": "AI development must align with legal frameworks and ethical guidelines. Developers should respect data privacy regulations (such as GDPR) and intellectual property rights; maintain auditable records of data and model provenance; and adopt risk management frameworks for responsible AI. Tools like data sheets and model cards improve transparency by documenting dataset and model motivation, composition and limitations\u3010196347673918349\u2020L122-L133\u3011\u3010196347673918349\u2020L137-L144\u3011.", "summary": "AI development must align with legal frameworks and ethical guidelines", "tags": ["compliance", "privacy"], "citations": [{"source_id": "s_turing_governance", "locator": "L122-L133"}, {"source_id": "s_turing_governance", "locator": "L137-L144"}]}
